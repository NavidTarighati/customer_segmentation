{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21606b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pythonProject1 (Python 3.8.18)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n pythonProject1 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "\n",
    "\n",
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#display ssettings\n",
    "pd.options.display.float_format = '{:20.2f}'.format\n",
    "\n",
    "#show all columns in output\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Data Exploration\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# Replace the absolute path with a relative path\n",
    "df = pd.read_excel(\"online_retail_II.xlsx\", sheet_name=0)\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "df.info()\n",
    "\n",
    "## customer ID has nulls\n",
    "\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "df.describe()\n",
    "\n",
    "\n",
    "# #### min quantity is -9600 and min price is -53594 which need further exploration\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "df.describe(include='O')\n",
    "\n",
    "\n",
    "# #### number of unique stock codes and descriptions are different and the count of descriptions is fewer which should be checked\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "df[df[\"Customer ID\"].isna()].head(10)\n",
    "\n",
    "\n",
    "# #### since we are focused on customer data, it would be better to remove null customer IDs.\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "df[df[\"Quantity\"]<0].head(10)\n",
    "\n",
    "\n",
    "# #### the invoices that start with C are for cancelled orders so they have negative quantities\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "df[\"Invoice\"] = df[\"Invoice\"].astype(\"str\")\n",
    "\n",
    "\n",
    "# #### Checking where the invoice number is not exactly 6 digits\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "df[df[\"Invoice\"].str.match(\"^\\\\d{6}$\")==False]\n",
    "\n",
    "\n",
    "# #### Checking if C in the beginning of invoice number is the only anomaly by taking out all digits and check if C is unique\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "df[\"Invoice\"].str.replace(\"[0-9]\", \"\", regex=True).unique()\n",
    "\n",
    "\n",
    "# #### We can see that in addition to cancelled orders that start with a C, there are orders that have the letter A in them\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "df[df[\"Invoice\"].str.startswith(\"A\")]\n",
    "\n",
    "\n",
    "# #### All these are described as \"adjust bad debt\" so these can be removed especially since the customer ID is NaN\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "df[\"StockCode\"]= df[\"StockCode\"].astype(\"str\")\n",
    "df[df[\"StockCode\"].str.match(\"^6\\\\d{5}$\")==False]\n",
    "\n",
    "\n",
    "# #### There are a very large number of Stock Codes which do not follow the pattern in the documentation which is 6 digits only\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "df[df[\"StockCode\"].str.match(\"^6\\\\d{5}$\") & df[\"StockCode\"].str.match(\"^6\\\\d{5}[a-zA-Z]+$\")==False]\n",
    "\n",
    "\n",
    "# ### Ideally, we want to check these unusual Stock Codes to find out if they are useful or not.\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "# Checking if we have stock codes that are not unique to a description\n",
    "df[df.duplicated(subset=[\"Description\"], keep=False)]\n",
    "\n",
    "\n",
    "\n",
    "# ## Data Cleaning\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "cleaned_df=df.copy()\n",
    "\n",
    "\n",
    "# #### Cleaning the invoices for cancellation and accounting. We don't need them since we are not working on sales but Customer Clustering\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "cleaned_df[\"Invoice\"]=cleaned_df[\"Invoice\"].astype(\"str\")\n",
    "# Create a filter expression\n",
    "mask = (\n",
    "\n",
    "    cleaned_df[\"Invoice\"].str.match(\"^\\\\d{6}$\") == True\n",
    ")\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "cleaned_df = cleaned_df[mask]\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "cleaned_df\n",
    "\n",
    "\n",
    "# #### Cleaning the Stock Codes\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "cleaned_df[\"StockCode\"]=cleaned_df[\"StockCode\"].astype(\"str\")\n",
    "# Create a filter expression\n",
    "mask = (\n",
    "    (cleaned_df[\"StockCode\"].str.match(\"^\\\\d{5}$\") == True) |\n",
    "    (cleaned_df[\"StockCode\"].str.match(\"^\\\\dd{5}[a-zA-Z]+$\") == True) |\n",
    "    (cleaned_df[\"StockCode\"].str.match(\"^PADS$\") == True) \n",
    ")\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "cleaned_df = cleaned_df[mask]\n",
    "cleaned_df\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# droping null customer values\n",
    "cleaned_df.dropna(subset=[\"Customer ID\"], inplace=True)\n",
    "\n",
    "\n",
    "# #### we need to check that negative price is removed\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "cleaned_df.describe()\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "## min price and quantity no more have negative values but Price has a min of 0\n",
    "cleaned_df[cleaned_df[\"Price\"]==0]\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "# How many of these records do we have?\n",
    "len(cleaned_df[cleaned_df[\"Price\"]==0])\n",
    "\n",
    "\n",
    "# #### we can't see any reason for the 0 price but it could be result of a giveaway or a sales event.\n",
    "# #### At this time, we remove them since we have no idea where they come from and they are only 27 instances\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "cleaned_df = cleaned_df[cleaned_df[\"Price\"]>0]\n",
    "cleaned_df.describe()\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "cleaned_df[\"Price\"].min()\n",
    "\n",
    "\n",
    "# #### seems like we have one row where the price is 0.0001 so it appears as a zero \n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "cleaned_df[cleaned_df[\"Price\"] ==0.001].head()\n",
    "\n",
    "\n",
    "# #### We can keep these in since there are only 5 of them\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "### Let's check how much data have we dropped during cleaning\n",
    "len(cleaned_df)/len(df)\n",
    "\n",
    "\n",
    "# ## We have dropped 33% of our data while cleaning\n",
    "\n",
    "# ### We want to explore RFM\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "# adding a total spent for each line\n",
    "cleaned_df[\"LineTotal\"]=cleaned_df[\"Quantity\"]*cleaned_df[\"Price\"]\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "cleaned_df\n",
    "\n",
    "\n",
    "# ### Creating RFM by aggregating our Data\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "aggregated_df = cleaned_df.groupby(by=\"Customer ID\", as_index=False) \\\n",
    "    .agg(\n",
    "        MonetaryValue=(\"LineTotal\",\"sum\"),\n",
    "        Frequency=(\"Invoice\",\"nunique\"),\n",
    "        LastInvoiceDate=(\"InvoiceDate\", \"max\")\n",
    ")\n",
    "aggregated_df.head(5)\n",
    "\n",
    "\n",
    "# #### Cleaning the Customer ID column datatype\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "max_invoice_date= aggregated_df[\"LastInvoiceDate\"].max()\n",
    "\n",
    "\n",
    "# ### Since data is old, I am using the latest invoice date as today for Recency\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "aggregated_df[\"Recency\"]= (max_invoice_date - aggregated_df[\"LastInvoiceDate\"]).dt.days\n",
    "\n",
    "aggregated_df.head(5)\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "aggregated_df.describe()\n",
    "\n",
    "\n",
    "# #### finding outliers\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(aggregated_df['MonetaryValue'], bins=10, color='skyblue', edgecolor='black')\n",
    "plt.title('Monetary Value Distribution')\n",
    "plt.xlabel('Monetary Value')\n",
    "plt.ylabel('count')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(aggregated_df['Frequency'], bins=10, color='lightgreen', edgecolor='black')\n",
    "plt.title('Frequency Distribution')\n",
    "plt.xlabel('Frequency Value')\n",
    "plt.ylabel('count')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(aggregated_df['Recency'], bins=10, color='salmon', edgecolor='black')\n",
    "plt.title('Recency Distribution')\n",
    "plt.xlabel('Recency Value')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(data=aggregated_df['MonetaryValue'], color= 'skyblue')\n",
    "plt.title('Monetary Value BoxPlot')\n",
    "plt.xlabel(\"Monetary Value\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(data=aggregated_df['Frequency'], color= 'lightgreen')\n",
    "plt.title('Frequency BoxPlot')\n",
    "plt.xlabel(\"Frequency\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(data=aggregated_df['Recency'], color= 'salmon')\n",
    "plt.title('Recency BoxPlot')\n",
    "plt.xlabel(\"Recency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### The outliers are high valued customers, so getting rid of them is a mistake when we are discussing customer segmentation\n",
    "# ### The proper way to go forward is to seperate them as their own cluster\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "aggregated_df\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "# writing new quartile range for Monetary Value\n",
    "M_Q1 = aggregated_df[\"MonetaryValue\"].quantile(0.25)\n",
    "M_Q3 = aggregated_df[\"MonetaryValue\"].quantile(0.75)\n",
    "M_IQR = M_Q3-M_Q1\n",
    "\n",
    "monetary_outliers_df= aggregated_df[(aggregated_df[\"MonetaryValue\"] > (M_Q3+ 1.5 * M_IQR))|(aggregated_df[\"MonetaryValue\"] < (M_Q1 - 1.5 * M_IQR))].copy()\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "monetary_outliers_df.describe()\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "# writing new quartile range for Frequency\n",
    "M_Q1 = aggregated_df[\"Frequency\"].quantile(0.25)\n",
    "M_Q3 = aggregated_df[\"Frequency\"].quantile(0.75)\n",
    "M_IQR = M_Q3-M_Q1\n",
    "\n",
    "frequency_outliers_df= aggregated_df[(aggregated_df[\"Frequency\"] > (M_Q3+ 1.5 * M_IQR))|(aggregated_df[\"Frequency\"] < (M_Q1 - 1.5 * M_IQR))].copy()\n",
    "frequency_outliers_df.describe()\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "# writing new quartile range for Recency\n",
    "M_Q1 = aggregated_df[\"Recency\"].quantile(0.25)\n",
    "M_Q3 = aggregated_df[\"Recency\"].quantile(0.75)\n",
    "M_IQR = M_Q3-M_Q1\n",
    "\n",
    "Recency_outliers_df= aggregated_df[(aggregated_df[\"Recency\"] > (M_Q3+ 1.5 * M_IQR))|(aggregated_df[\"Recency\"] < (M_Q1 - 1.5 * M_IQR))].copy()\n",
    "Recency_outliers_df.describe()\n",
    "\n",
    "\n",
    "# ## Let's find the non-outliers\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "#### Since we have not reset the indeces \n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "non_outliers_df = aggregated_df[(~aggregated_df.index.isin(monetary_outliers_df.index))&(~aggregated_df.index.isin(frequency_outliers_df.index))]\n",
    "non_outliers_df.describe()\n",
    "\n",
    "\n",
    "# ### There is a good amount of reduction of difference between mean and Std due to trimming the outliers\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(data=non_outliers_df['MonetaryValue'], color= 'skyblue')\n",
    "plt.title('Monetary Value BoxPlot')\n",
    "plt.xlabel(\"Monetary Value\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(data=non_outliers_df['Frequency'], color= 'lightgreen')\n",
    "plt.title('Frequency BoxPlot')\n",
    "plt.xlabel(\"Frequency\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(data=non_outliers_df['Recency'], color= 'salmon')\n",
    "plt.title('Recency BoxPlot')\n",
    "plt.xlabel(\"Recency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "scatter = ax.scatter(non_outliers_df[\"MonetaryValue\"],non_outliers_df[\"Frequency\"],non_outliers_df[\"Recency\"])\n",
    "\n",
    "ax.set_xlabel(\"Monetary Value\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_zlabel(\"Recency\")\n",
    "\n",
    "ax.set_title('3D Scatter Plot of Customer Data')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### !Important to notice that due to the difference of scales, the data is clustered in one corner\n",
    "# #### This matters since the Kmean cluster is sensitive and centroids will be shifted to monetary value\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "# we will use z score for rescaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "scaled_data = scaler.fit_transform(non_outliers_df[[\"MonetaryValue\", \"Frequency\",\"Recency\"]])\n",
    "scaled_data\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "scaled_data_df = pd.DataFrame(scaled_data, index=non_outliers_df.index, columns=(\"MonetaryValue\",\"Frequency\",\"Recency\"))\n",
    "scaled_data_df\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "scatter = ax.scatter(scaled_data_df[\"MonetaryValue\"],scaled_data_df[\"Frequency\"],scaled_data_df[\"Recency\"])\n",
    "\n",
    "ax.set_xlabel(\"Monetary Value\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_zlabel(\"Recency\")\n",
    "\n",
    "ax.set_title('3D Scatter Plot of Customer Data')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### We use Elbow methods in conjunction with silhouette to determine the value of k\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "# assign a max number of centroids\n",
    "max_k = 12\n",
    "\n",
    "inertia = []\n",
    "\n",
    "#define the range of possible k values\n",
    "k_values = range(2, max_k+1)\n",
    "\n",
    "for k in k_values:\n",
    "    \n",
    "    kmeans= KMeans(n_clusters=k, random_state=40, max_iter=1000)\n",
    "    \n",
    "    kmeans.fit_predict(scaled_data_df)\n",
    "    \n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(k_values, inertia, marker=\"o\")\n",
    "\n",
    "plt.title('KMeans Inertia for Different Values of k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #### We can see that the trajectory of the graph stabilizes near 4 and 5\n",
    "\n",
    "# ### Silhouette Score will help decide between 4 and 5\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "max_k = 12\n",
    "\n",
    "inertia = []\n",
    "silhouette_scores=[]\n",
    "#define the range of possible k values\n",
    "k_values = range(2, max_k+1)\n",
    "\n",
    "for k in k_values:\n",
    "    \n",
    "    kmeans= KMeans(n_clusters=k, random_state=42, max_iter=1000)\n",
    "    \n",
    "    cluster_labels=kmeans.fit_predict(scaled_data_df)\n",
    "    \n",
    "    sil_score= silhouette_score(scaled_data_df,cluster_labels)\n",
    "    \n",
    "    silhouette_scores.append(sil_score)\n",
    "    \n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(k_values, inertia, marker=\"o\")\n",
    "plt.title('KMeans Inertia for Different Values of k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(k_values, silhouette_scores, marker=\"o\", color='green')\n",
    "plt.title('Silhouette Scores for Different Values of k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette cores')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #### in the sillhouette scores graph, we can see that 4 is more stable than 5\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, max_iter=1000)\n",
    "\n",
    "cluster_labels = kmeans.fit_predict(scaled_data_df)\n",
    "\n",
    "cluster_labels\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "\n",
    "non_outliers_df[\"Cluster\"]=cluster_labels\n",
    "non_outliers_df\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "cluster_colors = {\n",
    "    0: '#1f77bf',\n",
    "    1: '#ff7f0e',\n",
    "    2: '#2ca02c',\n",
    "    3: '#d62728'\n",
    "}\n",
    "\n",
    "colors=non_outliers_df['Cluster'].map(cluster_colors)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax=fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    non_outliers_df['MonetaryValue'],\n",
    "    non_outliers_df['Frequency'],\n",
    "    non_outliers_df['Recency'],\n",
    "    c=colors,\n",
    "    marker='o'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "\n",
    "ax.set_title('3D Scatter Plot of Customer Data by Cluster')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### We can use a violin plot to drill down on each 3 axes\n",
    "\n",
    "# In[72]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 18))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.violinplot(x=non_outliers_df['Cluster'], y=non_outliers_df['MonetaryValue'], palette=cluster_colors, hue=non_outliers_df[\"Cluster\"])\n",
    "#sns.violinplot(y=non_outliers_df['MonetaryValue'], color='gray', linewidth=1.0)\n",
    "plt.title('Monetary Value by Cluster')\n",
    "plt.ylabel('Monetary Value')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.violinplot(x=non_outliers_df['Cluster'], y=non_outliers_df['Frequency'], palette=cluster_colors, hue=non_outliers_df[\"Cluster\"])\n",
    "#sns.violinplot(y=non_outliers_df['Frequency'], color='gray', linewidth=1.0)\n",
    "plt.title('Frequency by Cluster')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.violinplot(x=non_outliers_df['Cluster'], y=non_outliers_df['Recency'], palette=cluster_colors, hue=non_outliers_df[\"Cluster\"])\n",
    "#sns.violinplot(y=non_outliers_df['Recency'], color='gray', linewidth=1.0)\n",
    "plt.title('Recency by Cluster')\n",
    "plt.ylabel('Recency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
